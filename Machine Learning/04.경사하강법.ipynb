{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형 회귀식의 계수를 찾는 법 - OLS VS. SGD\n",
    "- 보스턴 집값 데이터 활용(RM VS Price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 필요한 라이브러리 import \n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 수집 및 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# 데이터 수집\n",
    "boston = load_boston()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "\n",
    "X = pd.DataFrame(df['RM'])\n",
    "y = boston.target\n",
    "\n",
    "# 전체 데이터 중 80%는 학습용, 20%는 검증용으로 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LinearRegression 모델을 사용한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.46109164] -30.571032410898336\n",
      "y = 8.461092X + -30.571\n",
      "MSE: 36.517\n",
      "RMSE:  6.043\n",
      "R2:  0.602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# 데이터 수집\n",
    "boston = load_boston()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df =pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "\n",
    "X = pd.DataFrame(df['RM'])\n",
    "y = boston.target\n",
    "\n",
    "# 전체 데이터 중 80%는 학습용, 20%는 검증용으로 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\\\n",
    "                                                   random_state=1)\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#모델 객체 생성\n",
    "reg = LinearRegression()\n",
    "\n",
    "# 모델 학습\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# 계수 및 절편 확인: _속성은 학습을 통해 결정되는 속성\n",
    "print(reg.coef_, reg.intercept_)\n",
    "\n",
    "#회귀식\n",
    "print(\"y = {:2f}X + {:.3f}\".format(reg.coef_[0], reg.intercept_))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 예측 수행\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# MSE, RMSE, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", np.round(mse, 3))\n",
    "print(\"RMSE: \", np.round(rmse, 3))\n",
    "print(\"R2: \", np.round(r2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SGDRegressor with Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.17660425] [-3.72330768]\n",
      "y = 4.176604X + -3.723\n",
      "MSE: 55.157\n",
      "RMSE:  7.427\n",
      "R2:  0.398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "reg = SGDRegressor()\n",
    "\n",
    "# 모델 학습\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# 계수 및 절편 확인: _속성은 학습을 통해 결정되는 속성\n",
    "print(reg.coef_, reg.intercept_)\n",
    "\n",
    "#회귀식\n",
    "print(\"y = {:2f}X + {:.3f}\".format(reg.coef_[0], reg.intercept_[0]))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 예측 수행\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# MSE, RMSE, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", np.round(mse, 3))\n",
    "print(\"RMSE: \", np.round(rmse, 3))\n",
    "print(\"R2: \", np.round(r2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.06320602] [-1.91124297]\n",
      "y = 4.063206X + -1.911\n",
      "MSE: 56.765\n",
      "RMSE:  7.534\n",
      "R2:  0.381\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "reg = SGDRegressor(max_iter = 1000, eta0 = 0.001, learning_rate='constant')\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# 계수 및 절편 확인: _속성은 학습을 통해 결정되는 속성\n",
    "print(reg.coef_, reg.intercept_)\n",
    "\n",
    "#회귀식\n",
    "print(\"y = {:2f}X + {:.3f}\".format(reg.coef_[0], reg.intercept_[0]))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 예측 수행\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# MSE, RMSE, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", np.round(mse, 3))\n",
    "print(\"RMSE: \", np.round(rmse, 3))\n",
    "print(\"R2: \", np.round(r2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.00524173e+11] [2.30369351e+11]\n",
      "y = -500524173235.820923X + 230369351230.944\n",
      "MSE: 8.841894147729339e+24\n",
      "RMSE:  2973532267813.709\n",
      "R2:  -9.646984481958484e+22\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "reg = SGDRegressor(max_iter = 1000, eta0 = 0.001, learning_rate='constant')\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# 계수 및 절편 확인: _속성은 학습을 통해 결정되는 속성\n",
    "print(reg.coef_, reg.intercept_)\n",
    "\n",
    "#회귀식\n",
    "print(\"y = {:2f}X + {:.3f}\".format(reg.coef_[0], reg.intercept_[0]))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 예측 수행\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# MSE, RMSE, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", np.round(mse, 3))\n",
    "print(\"RMSE: \", np.round(rmse, 3))\n",
    "print(\"R2: \", np.round(r2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 방 갯수, 크기, 편의시설에 대한 값의 크기 차이가 있을 수 있다. \"4개\", \"28평\", \"편의점2개\" 등등\n",
    "- 특성의 값 단위 차이가 클 경우, 경사하강법 할때 오류가 커진다.\n",
    "- 동일한 범위로 값을 맞춰주자 (변환) \n",
    "    - MinMax [0-1]\n",
    "    - 표준화 [(값-평균)/표준편차]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SGDRegressor with Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.84261376] [22.33855891]\n",
      "y = 5.842614X + 22.339\n",
      "MSE: 36.546\n",
      "RMSE:  6.045\n",
      "R2:  0.601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# 표준화 스케일링\n",
    "train_mean = np.mean(X_train,axis=0)\n",
    "train_std = np.std(X_train,axis=0)\n",
    "X_train = (X_train-train_mean) / train_std\n",
    "X_test = (X_test - train_mean) / train_std\n",
    "\n",
    "reg = SGDRegressor(max_iter = 1000, eta0 = 0.001, learning_rate='constant')\n",
    "\n",
    "# 모델 학습\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# 계수 및 절편 확인: _속성은 학습을 통해 결정되는 속성\n",
    "print(reg.coef_, reg.intercept_)\n",
    "\n",
    "#회귀식\n",
    "print(\"y = {:2f}X + {:.3f}\".format(reg.coef_[0], reg.intercept_[0]))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 예측 수행\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# MSE, RMSE, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", np.round(mse, 3))\n",
    "print(\"RMSE: \", np.round(rmse, 3))\n",
    "print(\"R2: \", np.round(r2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SGDRegressor with StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.86455022] [22.34880813]\n",
      "y = 5.864550X + 22.349\n",
      "MSE: 36.485\n",
      "RMSE:  6.04\n",
      "R2:  0.602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#표준화스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "reg = SGDRegressor(max_iter = 1000, eta0 = 0.001, learning_rate='constant')\n",
    "\n",
    "# 모델 학습\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# 계수 및 절편 확인: _속성은 학습을 통해 결정되는 속성\n",
    "print(reg.coef_, reg.intercept_)\n",
    "\n",
    "#회귀식\n",
    "print(\"y = {:2f}X + {:.3f}\".format(reg.coef_[0], reg.intercept_[0]))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 예측 수행\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# MSE, RMSE, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", np.round(mse, 3))\n",
    "print(\"RMSE: \", np.round(rmse, 3))\n",
    "print(\"R2: \", np.round(r2, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
